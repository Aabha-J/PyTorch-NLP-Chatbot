{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNncic3kVFwGiQMdUPygYHt"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dependancies\n"
      ],
      "metadata": {
        "id": "eajlNzdN8FSb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rEu7RLQ46PCS",
        "outputId": "7efea44f-b310-4f2a-a733-f3b36ce94bc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import json\n",
        "import numpy as np\n",
        "nltk.download('punkt')  # uncomment this if it's not downloaded, comment it out again after downloading\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "r07Atu4a6x2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define Hyperaramters"
      ],
      "metadata": {
        "id": "SpvQ4ExM88SZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 8\n",
        "WORKERS = 2\n",
        "HIDDEN_SIZE = 8\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 800"
      ],
      "metadata": {
        "id": "UMM-MJGV6fqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "j7wgv_qR-cLO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Process Input Data"
      ],
      "metadata": {
        "id": "Q8SmZhgQ9C7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    return nltk.word_tokenize(text)\n",
        "\n",
        "def stem(word):\n",
        "    # Lowercases the word and stemming\n",
        "    return stemmer.stem(word.lower())\n",
        "\n",
        "def bag_of_words(tokenized_words, all_words):\n",
        "    \"\"\"\n",
        "    tokenized_words: [\"hello\", how\", \"are\", \"you\"]\n",
        "    all_words: [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n",
        "    returns: [0, 1, 0, 1, 0, 0, 0]\n",
        "    \"\"\"\n",
        "    tokenized_words = [stem(w) for w in tokenized_words]\n",
        "    bag = np.zeros(len(all_words), dtype=np.float32) #[0, 0, 0, 0, 0, 0, 0]\n",
        "    for idx, w in enumerate(all_words):\n",
        "        if w in tokenized_words:\n",
        "            bag[idx] = 1.0        #Flips the them to 1\n",
        "    return bag\n",
        "\n",
        "def get_json_data():\n",
        "    with open(\"intents.json\", \"r\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "\n",
        "    all_words = []\n",
        "    tags = []\n",
        "    xy = []\n",
        "    for intent in data[\"intents\"]:\n",
        "        tag = intent[\"tag\"]\n",
        "        tags.append(tag)\n",
        "\n",
        "        # 1. Tokenization\n",
        "        for pattern in intent[\"patterns\"]:\n",
        "            w = tokenize(pattern)\n",
        "            all_words.extend(w) # extend adds all the elements of w to all_words\n",
        "            xy.append((w, tag))\n",
        "\n",
        "    ignore_words = [\"?\", \"!\", \".\", \",\"]\n",
        "\n",
        "\n",
        "    #2. Lowercasing (done in stemming function) and 3. Stemming and\n",
        "    all_words = [stem(w) for w in all_words if w not in ignore_words] #4. Remove Punctuation\n",
        "    all_words = sorted(set(all_words))\n",
        "    tags = sorted(set(tags))\n",
        "\n",
        "    # print(len(xy), \"patterns\")\n",
        "    # print(len(tags), \"tags:\", tags)\n",
        "    # print(len(all_words), \"unique stemmed words:\", all_words)\n",
        "\n",
        "    return all_words, tags, xy, data"
      ],
      "metadata": {
        "id": "RxoKtKf167mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Neural Network Class\n"
      ],
      "metadata": {
        "id": "AfrcrCHg9IOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.l3 = nn.Linear(hidden_size, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.l3(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "xxbnqZ_i7B_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset Class"
      ],
      "metadata": {
        "id": "TfHQspCi9OAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.n_samples = len(x)\n",
        "        self.x_data = x\n",
        "        self.y_data = y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples"
      ],
      "metadata": {
        "id": "MjxL-tcl7RN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get Training Data"
      ],
      "metadata": {
        "id": "MZb0nGAr9WwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_data():\n",
        "    all_words, tags, xy, intents = get_json_data()\n",
        "\n",
        "    X_train = []\n",
        "    Y_train = []\n",
        "\n",
        "    for (pattern, tag) in xy:\n",
        "        bag = bag_of_words(pattern, all_words)\n",
        "        X_train.append(bag)\n",
        "\n",
        "        label = tags.index(tag)\n",
        "        Y_train.append(label)\n",
        "\n",
        "    X_train = np.array(X_train)\n",
        "    Y_train = np.array(Y_train)\n",
        "\n",
        "    return X_train, Y_train, tags"
      ],
      "metadata": {
        "id": "tK6lHMSD7Vfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Loop"
      ],
      "metadata": {
        "id": "xtgSf0Kc9afk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "  for epoch in range(EPOCHS):\n",
        "      for (words, labels) in train_loader:\n",
        "          words = words.to(device)\n",
        "          labels = labels.to(dtype=torch.long).to(device)\n",
        "\n",
        "          #forward pass\n",
        "          outputs = model(words)\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          #backward and optimizer step\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "      if (epoch + 1) % 100 == 0:\n",
        "          print(f'epoch {epoch + 1}/{EPOCHS}, loss={loss.item():.3f}')\n",
        "\n",
        "  print(f'Final Loss, loss={loss.item():.3f}')\n"
      ],
      "metadata": {
        "id": "ENZpLyhs7avN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Set Up"
      ],
      "metadata": {
        "id": "NG_tKEks_JPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train, tags = get_training_data()\n",
        "\n",
        "dataset = ChatDataset(x=X_train, y=Y_train)\n",
        "train_loader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS)\n",
        "\n",
        "model = NeuralNet(input_size=len(X_train[0]), hidden_size=HIDDEN_SIZE, num_classes=len(tags))\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhK7ns2C_EqR",
        "outputId": "45d45652-8cfd-43e2-8dcb-c5d0b614ae68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNet(\n",
              "  (l1): Linear(in_features=81, out_features=8, bias=True)\n",
              "  (l2): Linear(in_features=8, out_features=8, bias=True)\n",
              "  (l3): Linear(in_features=8, out_features=8, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xy1Aodqj7peH",
        "outputId": "77bef0c5-6616-4439-caa8-4b9a6276bd6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 100/800, loss=0.361\n",
            "epoch 200/800, loss=0.316\n",
            "epoch 300/800, loss=0.002\n",
            "epoch 400/800, loss=0.003\n",
            "epoch 500/800, loss=0.010\n",
            "epoch 600/800, loss=0.001\n",
            "epoch 700/800, loss=0.001\n",
            "epoch 800/800, loss=0.000\n",
            "Final Loss, loss=0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save the Model"
      ],
      "metadata": {
        "id": "L9aydKBT9gAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_words, tags, xy, intents = get_json_data()\n",
        "\n",
        "data = {\n",
        "    \"model_state\": model.state_dict(),\n",
        "    \"input_size\": len(X_train[0]),\n",
        "    \"hidden_size\": HIDDEN_SIZE,\n",
        "    \"output_size\": len(tags),\n",
        "    \"all_words\": all_words,\n",
        "    \"tags\": tags\n",
        "}\n",
        "\n",
        "FILE = \"data.pth\"\n",
        "torch.save(data, FILE)\n"
      ],
      "metadata": {
        "id": "hXZ0_acl9koa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load and Run Model"
      ],
      "metadata": {
        "id": "p6GYAHihCrDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(file_name):\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "  with open(\"intents.json\", \"r\") as f:\n",
        "      intents = json.load(f)\n",
        "\n",
        "  data = torch.load(file_name)\n",
        "\n",
        "  input_size = data[\"input_size\"]\n",
        "  hidden_size = data[\"hidden_size\"]\n",
        "  output_size = data[\"output_size\"]\n",
        "  all_words = data[\"all_words\"]\n",
        "  tags = data[\"tags\"]\n",
        "  model_state = data[\"model_state\"]\n",
        "\n",
        "  model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
        "  model.load_state_dict(model_state)\n",
        "  model.eval()\n",
        "  return model, all_words, tags, intents"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_p1OqKkYCoq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bot_name = \"Axel\"\n",
        "print(f\"Hi I'm {bot_name} Let's chat! (type 'quit' to exit)\")\n",
        "chat_model, all_words, tags, intents = load_model(\"data.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrhaiyuUEcyl",
        "outputId": "f9c19a13-394b-4f60-f08d-9d262a996448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's Chat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "OzMtti-aIj87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(model, all_words, tags, sentence, intents):\n",
        "    sentence = tokenize(sentence)\n",
        "    X = bag_of_words(sentence, all_words)\n",
        "    X = X.reshape(1, X.shape[0])\n",
        "    X = torch.from_numpy(X).to(device)\n",
        "\n",
        "    output = model(X)\n",
        "\n",
        "    _, predicted = torch.max(output, dim=1)\n",
        "\n",
        "    tag = tags[predicted.item()]\n",
        "\n",
        "    probs = torch.softmax(output, dim=1)\n",
        "    prob = probs[0][predicted.item()]\n",
        "    if prob.item() > 0.75:\n",
        "        for intent in intents['intents']:\n",
        "            if tag == intent[\"tag\"]:\n",
        "                return random.choice(intent['responses'])\n",
        "\n",
        "    return \"I do not understand. Can you please try another question or rephrase your question\""
      ],
      "metadata": {
        "id": "DBefeiFGO04Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  sentence = input()\n",
        "  if sentence == \"quit\":\n",
        "    break\n",
        "\n",
        "  print(f\"{bot_name} : {get_response(model, all_words, tags, sentence, intents)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idXvsUwkPVkY",
        "outputId": "ef406b9c-4b45-4df5-9b8d-09be00142863"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hi\n",
            "Axel : Hi there, how can I help?\n",
            "vhnvnhn\n",
            "Axel : Hi there, what can I do for you?\n",
            "tell me a joke\n",
            "Axel : Why don't scientists trust atoms? Because they make up everything!\n",
            "how do i pay\n",
            "Axel : We accept VISA, Mastercard, American Express and Paypal\n",
            "can i pay with cash\n",
            "Axel : We accept most major credit cards, and Paypal\n",
            "quit\n"
          ]
        }
      ]
    }
  ]
}